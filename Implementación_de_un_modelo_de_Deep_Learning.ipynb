{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementaci√≥n de un modelo de Deep Learning"
      ],
      "metadata": {
        "id": "WzxVclfYof0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRa53RpC036s",
        "outputId": "a7480e63-bd3a-424f-aadc-7526f9dcb0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/IA\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#%cd \"/content/drive/MyDrive/IA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "6IrEnA88Dfdc",
        "outputId": "606be85e-6608-489a-b416-4fbe0185ea15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26018d74-528f-4c96-bf5b-407bbac69f94\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26018d74-528f-4c96-bf5b-407bbac69f94\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"a01378649\",\"key\":\"1dca8bf62fee4ec115bdb3be7cbe32ca\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T7__eIp5JS8N"
      },
      "outputs": [],
      "source": [
        "!rm -rf ~/.kaggle "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y6YE08NGHQLD"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a1HpTU6HgMR",
        "outputId": "549f99b7-649f-4a99-d9b4-22fa623e8e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                             title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                       COVID-19 Dataset                                      5MB  2022-11-13 15:47:17           4854        154  1.0              \n",
            "mvieira101/global-cost-of-living                                Global Cost of Living                                 1MB  2022-12-03 16:37:53            699         34  0.9705882        \n",
            "akshaydattatraykhare/diabetes-dataset                           Diabetes Dataset                                      9KB  2022-10-06 08:55:25          21282        573  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                       Salary Prediction                                     3MB  2022-11-16 13:52:31           3313         79  1.0              \n",
            "fuarresvij/gdp-growth-around-the-globe                          GDP Growth around the Globe                         122KB  2022-11-22 00:36:28           1214         38  0.9411765        \n",
            "akshaydattatraykhare/data-for-admission-in-the-university       Data for Admission in the University                  4KB  2022-10-27 11:05:45           7124        159  1.0              \n",
            "arthurboari/taylor-swift-spotify-data                           Taylor Swift Spotify Data                            96KB  2022-11-21 13:46:01            726         27  0.9705882        \n",
            "dsfelix/us-stores-sales                                         US Stores Sales                                      84KB  2022-11-08 00:11:06           1776         30  1.0              \n",
            "thedevastator/fashion-products-on-amazon-ratings-prices-and-pa  Fashion Products on Amazon: Ratings, Prices, etc      8MB  2022-11-18 14:28:57           1306         34  1.0              \n",
            "whenamancodes/predict-diabities                                 Predict Diabetes                                      9KB  2022-11-09 12:18:49           3807         78  1.0              \n",
            "prosperchuks/health-dataset                                     Diabetes, Hypertension and Stroke Prediction        597KB  2022-11-23 10:04:03           1447         35  1.0              \n",
            "thedevastator/cancer-patients-and-air-pollution-a-new-link       Lung Cancer Prediction                               7KB  2022-11-14 13:40:40           2328         58  1.0              \n",
            "dbarteaux99/stable-diffusion-1-5                                Stable Diffusion 1.5 (normal and EMAonly) with vae    7GB  2022-10-23 15:40:29            102         20  0.9375           \n",
            "piterfm/fifa-football-world-cup                                 FIFA Football World Cup                              77KB  2022-12-04 12:20:48           1903         57  1.0              \n",
            "whenamancodes/credit-card-customers-prediction                  Credit Card Customers Prediction                    379KB  2022-10-30 13:03:27           4189         88  1.0              \n",
            "mukhazarahmad/worldwide-cancer-data                             Worldwide cancer data                                 2KB  2022-11-13 03:06:15            772         31  1.0              \n",
            "shilongzhuang/-women-clothing-ecommerce-sales-data              üè∑Ô∏èüëö Women Clothing Ecommerce Sales Data               5KB  2022-11-21 01:27:59            659         27  1.0              \n",
            "thedevastator/empowering-the-next-wave-of-entrepreneurs         US Startup companies over time (Timeseries)         974KB  2022-11-16 16:11:01            875         30  1.0              \n",
            "zvr842/global-pollution-by-counties                             Global pollution by counties                         15KB  2022-11-14 10:57:31           1865         41  0.9705882        \n",
            "dheerajmukati/india-gdp-19602022                                India GDP 1960-2022                                   1KB  2022-11-11 12:08:46           1516         48  1.0              \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecci√≥n de dataset\n",
        "\n",
        "Se escoger√° la base de SVHN que contiene im√°genes RGB de n√∫meros en diferentes lugares del mundo real. Asimismo, existe ruido alrededor como parte del ambiente, o incluso otros n√∫meros. En este caso, solo nos interesa categorizar el n√∫mero m√°s centrado."
      ],
      "metadata": {
        "id": "cB51Hil1pFgK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoaxJc5JHhm1",
        "outputId": "ea3af18d-4cf1-41a3-eaea-dbeec5045a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "svhndataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d quanbk/svhndataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psCD7RgMKZ0S",
        "outputId": "2bfe1f59-e29d-47fe-c1e8-a63b87925b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  svhndataset.zip\n",
            "replace extra_32x32.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test_32x32.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train_32x32.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "!unzip svhndataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cDn4LUBcLODy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La base de datos incluye por defecto el set de entrenamiento y prueba, no obstante, hace falta alinear los datos para ser consumidos por el modelo. (Formatear a NHWC)"
      ],
      "metadata": {
        "id": "8E_d5evcqewu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ISrO0TLy6p",
        "outputId": "1ca335a5-4e6c-47a3-acc8-c7f956e54f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3, 73257)\n",
            "(32, 32, 3, 26032)\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "\n",
        "train_raw = loadmat('train_32x32.mat')\n",
        "test_raw = loadmat('test_32x32.mat')\n",
        "\n",
        "train_images = np.array(train_raw['X'])\n",
        "test_images = np.array(test_raw['X'])\n",
        "train_labels = train_raw['y']\n",
        "test_labels = test_raw['y']\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FckzIleXMrlO",
        "outputId": "2d20f15a-8980-4520-bd64-d06ab1d1768c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(73257, 32, 32, 3)\n",
            "(26032, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "train_images = np.moveaxis(train_images, -1, 0)\n",
        "test_images = np.moveaxis(test_images, -1, 0)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como anteriormente se explica, aunque existan dos n√∫meros, el label provisto solo hace referencia al n√∫mero del centro."
      ],
      "metadata": {
        "id": "kVDKToQJfsFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "KsR_bg7LOPMi",
        "outputId": "96a15e9b-97f9-4055-8d7e-892a063764e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  [3]\n"
          ]
        }
      ],
      "source": [
        "#Probando que las im√°genes se hayan cargado de manera correcta\n",
        "plt.imshow(train_images[8])\n",
        "plt.show()\n",
        "\n",
        "print('Label: ', train_labels[8])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utilizar√° One-Hot Encoding para representar las categor√≠as (0 al 9)"
      ],
      "metadata": {
        "id": "AyXvAenYrNcj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ERDX_jTDPBMH"
      },
      "outputs": [],
      "source": [
        "lb = LabelBinarizer()\n",
        "train_labels = lb.fit_transform(train_labels)\n",
        "test_labels = lb.fit_transform(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos el set de entrenamiento inicial para crear el split de entrenamiento y validaci√≥n para el modelo. (85% y 15% respectivamente)"
      ],
      "metadata": {
        "id": "axV4QekIsIBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6lW5FkLiPTkB"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels,\n",
        "                                                  test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto confirmamos el n√∫mero y dimensiones para los conjuntos de entrenamiento y validaci√≥n."
      ],
      "metadata": {
        "id": "CzyfCPnBsCz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVHIZ6EuPoW9",
        "outputId": "5f692d89-eba1-42bf-9fe4-1857d6d92e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(62268, 32, 32, 3)\n",
            "(10989, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para incrementar el dominio de la naturaleza de las im√°genes, a√±adiremos una capa de data augmentation para prevenir overfitting. Cabe destacar que solo se aplica rotaci√≥n y zoom aleatorios para no cambiar efectivamente la categor√≠a de la imagen. Por ejemplo, no se le pone random flip porque el n√∫mero dejar√≠a de ser reconocible."
      ],
      "metadata": {
        "id": "zhItNXyOuJQT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3oYsDF3ePxPh"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomRotation(0.2),\n",
        "        layers.RandomZoom(0.2)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definici√≥n del modelo\n",
        "\n",
        "Se opt√≥ por el uso de una CNN tradicional de seis capas principales de convoluci√≥n. Se utiliza BatchNormalization para establizar el comportamiento durante el entrenamiento. Adem√°s, Se utilizan capas de MaxPooling intermedias para realizar downsampling y agilizar el c√≥mputo de predicciones, de igual manera, sirve para atenuar varianzas en la imagen como rotaci√≥n o el zoom que puede suceder naturalmente. Igualmente, se a√±aden capas de Dropout para prevenir overfitting. \n",
        "\n",
        "Finalmente, los datos procesados son utilizados por una capa de softmax que predice la categor√≠a."
      ],
      "metadata": {
        "id": "WT2u6zypu1vK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e0gdumKVQeWh"
      },
      "outputs": [],
      "source": [
        "#Se define una funci√≥n que regresa la arquitectura en limpio cada vez que se llama\n",
        "def Model1():\n",
        "    return keras.Sequential([\n",
        "    data_augmentation,\n",
        "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
        "                           activation='relu',\n",
        "                           input_shape=(32, 32, 3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
        "                        activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    \n",
        "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
        "                           activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same',\n",
        "                        activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same', \n",
        "                           activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same',\n",
        "                        activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10,  activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No se utiliz√≥ ninguna t√©cnica en especial para determinar el mejor learning rate (hyperparameter tunning), no obstante se sabe que para las CNN √©ste tiene que ser particularmente bajo, por lo que se decidi√≥ establecerlo como 0.001."
      ],
      "metadata": {
        "id": "PQJt-hs7C6dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = Model1()\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
        "optimizer = keras.optimizers.Adam(lr=0.001, amsgrad=True)\n",
        "m1.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjqSpzhH0EKP",
        "outputId": "815863f2-240f-4414-91a7-9e72d82b2864"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4nN6VbCdC3zR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB4Xh8vNilev",
        "outputId": "2d474115-af69-41f5-ca8f-a740010162c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "487/487 [==============================] - 17s 15ms/step - loss: 2.2588 - accuracy: 0.1971 - val_loss: 1.6696 - val_accuracy: 0.4624\n",
            "Epoch 2/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 1.2731 - accuracy: 0.5689 - val_loss: 0.7322 - val_accuracy: 0.7662\n",
            "Epoch 3/40\n",
            "487/487 [==============================] - 9s 18ms/step - loss: 0.8175 - accuracy: 0.7376 - val_loss: 0.5490 - val_accuracy: 0.8264\n",
            "Epoch 4/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.6888 - accuracy: 0.7802 - val_loss: 0.4973 - val_accuracy: 0.8428\n",
            "Epoch 5/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.6303 - accuracy: 0.8014 - val_loss: 0.4714 - val_accuracy: 0.8502\n",
            "Epoch 6/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5862 - accuracy: 0.8145 - val_loss: 0.4984 - val_accuracy: 0.8420\n",
            "Epoch 7/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5636 - accuracy: 0.8225 - val_loss: 0.3846 - val_accuracy: 0.8814\n",
            "Epoch 8/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5429 - accuracy: 0.8300 - val_loss: 0.4085 - val_accuracy: 0.8739\n",
            "Epoch 9/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5208 - accuracy: 0.8371 - val_loss: 0.3813 - val_accuracy: 0.8839\n",
            "Epoch 10/40\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5098 - accuracy: 0.8393 - val_loss: 0.3671 - val_accuracy: 0.8899\n",
            "Epoch 11/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.4967 - accuracy: 0.8446 - val_loss: 0.3544 - val_accuracy: 0.8917\n",
            "Epoch 12/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4844 - accuracy: 0.8481 - val_loss: 0.3454 - val_accuracy: 0.8957\n",
            "Epoch 13/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4794 - accuracy: 0.8519 - val_loss: 0.3444 - val_accuracy: 0.8961\n",
            "Epoch 14/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4681 - accuracy: 0.8546 - val_loss: 0.3935 - val_accuracy: 0.8811\n",
            "Epoch 15/40\n",
            "487/487 [==============================] - 9s 19ms/step - loss: 0.4635 - accuracy: 0.8563 - val_loss: 0.3419 - val_accuracy: 0.8968\n",
            "Epoch 16/40\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.4636 - accuracy: 0.8580 - val_loss: 0.3349 - val_accuracy: 0.8998\n",
            "Epoch 17/40\n",
            "487/487 [==============================] - 9s 18ms/step - loss: 0.4522 - accuracy: 0.8600 - val_loss: 0.3412 - val_accuracy: 0.8974\n",
            "Epoch 18/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4460 - accuracy: 0.8618 - val_loss: 0.3227 - val_accuracy: 0.9066\n",
            "Epoch 19/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4406 - accuracy: 0.8634 - val_loss: 0.3693 - val_accuracy: 0.8869\n",
            "Epoch 20/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.4380 - accuracy: 0.8636 - val_loss: 0.3221 - val_accuracy: 0.9029\n",
            "Epoch 21/40\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.4290 - accuracy: 0.8670 - val_loss: 0.3138 - val_accuracy: 0.9062\n",
            "Epoch 22/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.4304 - accuracy: 0.8657 - val_loss: 0.3208 - val_accuracy: 0.9068\n",
            "Epoch 23/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.4254 - accuracy: 0.8695 - val_loss: 0.3345 - val_accuracy: 0.8995\n",
            "Epoch 24/40\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.4217 - accuracy: 0.8700 - val_loss: 0.2999 - val_accuracy: 0.9106\n",
            "Epoch 25/40\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.4169 - accuracy: 0.8715 - val_loss: 0.3217 - val_accuracy: 0.9019\n",
            "Epoch 26/40\n",
            "487/487 [==============================] - 9s 18ms/step - loss: 0.4201 - accuracy: 0.8702 - val_loss: 0.2991 - val_accuracy: 0.9119\n",
            "Epoch 27/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4109 - accuracy: 0.8723 - val_loss: 0.2909 - val_accuracy: 0.9170\n",
            "Epoch 28/40\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.4109 - accuracy: 0.8742 - val_loss: 0.3086 - val_accuracy: 0.9099\n",
            "Epoch 29/40\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.4071 - accuracy: 0.8748 - val_loss: 0.2951 - val_accuracy: 0.9153\n",
            "Epoch 30/40\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.4021 - accuracy: 0.8769 - val_loss: 0.2871 - val_accuracy: 0.9161\n",
            "Epoch 31/40\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.4016 - accuracy: 0.8768 - val_loss: 0.3064 - val_accuracy: 0.9128\n",
            "Epoch 32/40\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.4009 - accuracy: 0.8774 - val_loss: 0.2928 - val_accuracy: 0.9140\n",
            "Epoch 33/40\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.3997 - accuracy: 0.8774 - val_loss: 0.2847 - val_accuracy: 0.9143\n",
            "Epoch 34/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.3965 - accuracy: 0.8774 - val_loss: 0.3001 - val_accuracy: 0.9107\n",
            "Epoch 35/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.3923 - accuracy: 0.8779 - val_loss: 0.2918 - val_accuracy: 0.9166\n",
            "Epoch 36/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.3932 - accuracy: 0.8779 - val_loss: 0.2831 - val_accuracy: 0.9180\n",
            "Epoch 37/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.3886 - accuracy: 0.8801 - val_loss: 0.2866 - val_accuracy: 0.9170\n",
            "Epoch 38/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.3883 - accuracy: 0.8812 - val_loss: 0.2835 - val_accuracy: 0.9162\n",
            "Epoch 39/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.3840 - accuracy: 0.8814 - val_loss: 0.2747 - val_accuracy: 0.9213\n",
            "Epoch 40/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.3868 - accuracy: 0.8803 - val_loss: 0.3565 - val_accuracy: 0.8891\n"
          ]
        }
      ],
      "source": [
        "history = m1.fit(X_train, y_train, batch_size=128,\n",
        "                              epochs=40, validation_data=(X_val, y_val),\n",
        "                              callbacks=[early_stopping]) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwF2b6kRkRiQ",
        "outputId": "2b2eb81a-339f-4112-89f7-7b2c03b62cd4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,506\n",
            "Trainable params: 122,250\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se muestra el accuracy del modelo, comparando su desempe√±o en el set de entrenamiento y validaci√≥n. En este caso, se observa que ambos tienen pendiente positiva en todo momento. No existe una disparidad sustancial en ambas magnitudes por lo que no se trata de underfitting u overfitting. Cabe destacar que el accuracy de entrenamiento es m√°s estable que el de validaci√≥n, pero el segundo se mantiene lo suficiente para mantener la tendencia. Inclusive se puede apreciar menos variabilidad en las √∫ltimas √©pocas."
      ],
      "metadata": {
        "id": "_Ht4kw8dDugo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Epochs vs. Training and Validation Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "wuw3unbX0iXt",
        "outputId": "ca20109d-06fd-40c5-93b2-fd14255bad05"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Epochs vs. Training and Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n del modelo\n",
        "\n",
        "Para apreciar el comportamiento del modelo durante y al final del entrenamiento, se utilizar√° el KFold cross-validation para analizar su consistencia. Para ello, se determinar√° el accuracy promedio y su desviaci√≥n est√°ndar de todas las instancias experimentales. En este caso, tanto un accuracy promedio alto y una desviaci√≥n est√°ndar baja (qu√© tan entrenable es) apuntan a un modelo con mejor desempe√±o."
      ],
      "metadata": {
        "id": "qW8NrobU0-D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "PPfeDmKk2RIz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En contraste a la primera instancia del modelo, cada iteraci√≥n del KFold se entrener√°n solo durante 30 √©pocas."
      ],
      "metadata": {
        "id": "jg6QfWmnGKTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#80% train y 20% validation\n",
        "n_split = 5\n",
        "k_eval = []\n",
        "\n",
        "for train_i ,val_i in KFold(n_split).split(train_images):\n",
        "  x_train,x_val= train_images[train_i], train_images[val_i]\n",
        "  y_t,y_v= train_labels[train_i], train_labels[val_i]\n",
        "\n",
        "  aux = Model1()\n",
        "\n",
        "  aux.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  aux.fit(x_train, y_t,epochs=30)\n",
        "\n",
        "  eval = aux.evaluate(x_val,y_v)\n",
        "  k_eval.append(eval[1])\n",
        "\n",
        "print('Model evaluation ', eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTE3CkPk1_nM",
        "outputId": "77cd8912-3c39-4d79-974e-3dbd1c169319"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 2.2361 - accuracy: 0.1990\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 1.3373 - accuracy: 0.5490\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.8466 - accuracy: 0.7276\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.7314 - accuracy: 0.7672\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 0.6687 - accuracy: 0.7891\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.6327 - accuracy: 0.8005\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5984 - accuracy: 0.8102\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5797 - accuracy: 0.8178\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5562 - accuracy: 0.8242\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5385 - accuracy: 0.8302\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5292 - accuracy: 0.8347\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5220 - accuracy: 0.8365\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5133 - accuracy: 0.8407\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5014 - accuracy: 0.8426\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4920 - accuracy: 0.8458\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4895 - accuracy: 0.8471\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4805 - accuracy: 0.8494\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4748 - accuracy: 0.8529\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4720 - accuracy: 0.8536\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4726 - accuracy: 0.8550\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4560 - accuracy: 0.8575\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4580 - accuracy: 0.8569\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4514 - accuracy: 0.8600\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4517 - accuracy: 0.8600\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4449 - accuracy: 0.8623\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4392 - accuracy: 0.8646\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4419 - accuracy: 0.8642\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4346 - accuracy: 0.8655\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4365 - accuracy: 0.8654\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4319 - accuracy: 0.8654\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.3104 - accuracy: 0.9103\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 2.2430 - accuracy: 0.1913\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.2870 - accuracy: 0.5685\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.8226 - accuracy: 0.7348\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.7072 - accuracy: 0.7747\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6512 - accuracy: 0.7938\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6146 - accuracy: 0.8068\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5863 - accuracy: 0.8134\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5622 - accuracy: 0.8233\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5481 - accuracy: 0.8271\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5281 - accuracy: 0.8354\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5196 - accuracy: 0.8363\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5071 - accuracy: 0.8413\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4978 - accuracy: 0.8455\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4854 - accuracy: 0.8478\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4851 - accuracy: 0.8485\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4779 - accuracy: 0.8513\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4674 - accuracy: 0.8538\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4651 - accuracy: 0.8560\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4593 - accuracy: 0.8591\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4538 - accuracy: 0.8586\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4503 - accuracy: 0.8609\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4474 - accuracy: 0.8633\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4402 - accuracy: 0.8620\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4410 - accuracy: 0.8619\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4356 - accuracy: 0.8638\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4334 - accuracy: 0.8667\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4265 - accuracy: 0.8690\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4217 - accuracy: 0.8707\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4207 - accuracy: 0.8694\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4233 - accuracy: 0.8700\n",
            "458/458 [==============================] - 2s 3ms/step - loss: 0.3227 - accuracy: 0.9032\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 2.2415 - accuracy: 0.1878\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.4428 - accuracy: 0.5046\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.8513 - accuracy: 0.7231\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.7345 - accuracy: 0.7643\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6715 - accuracy: 0.7867\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6244 - accuracy: 0.8030\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6013 - accuracy: 0.8088\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5809 - accuracy: 0.8170\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5609 - accuracy: 0.8241\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.5416 - accuracy: 0.8300\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5332 - accuracy: 0.8333\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5168 - accuracy: 0.8390\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5083 - accuracy: 0.8399\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5043 - accuracy: 0.8418\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4952 - accuracy: 0.8468\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4885 - accuracy: 0.8479\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4802 - accuracy: 0.8491\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4703 - accuracy: 0.8530\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4646 - accuracy: 0.8564\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4603 - accuracy: 0.8574\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4603 - accuracy: 0.8572\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4582 - accuracy: 0.8586\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4500 - accuracy: 0.8605\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4452 - accuracy: 0.8622\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4456 - accuracy: 0.8618\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4437 - accuracy: 0.8628\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4381 - accuracy: 0.8644\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4333 - accuracy: 0.8670\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4313 - accuracy: 0.8674\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 6ms/step - loss: 0.4249 - accuracy: 0.8676\n",
            "458/458 [==============================] - 2s 3ms/step - loss: 0.3174 - accuracy: 0.9070\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 2.2337 - accuracy: 0.1937\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.3078 - accuracy: 0.5551\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.8186 - accuracy: 0.7357\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.7114 - accuracy: 0.7730\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6468 - accuracy: 0.7966\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.6046 - accuracy: 0.8080\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5807 - accuracy: 0.8177\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5622 - accuracy: 0.8244\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5401 - accuracy: 0.8312\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5278 - accuracy: 0.8341\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5129 - accuracy: 0.8396\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5053 - accuracy: 0.8422\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4966 - accuracy: 0.8459\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4843 - accuracy: 0.8484\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4768 - accuracy: 0.8514\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4717 - accuracy: 0.8534\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4663 - accuracy: 0.8557\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4601 - accuracy: 0.8576\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4521 - accuracy: 0.8608\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 0.4544 - accuracy: 0.8604\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4412 - accuracy: 0.8634\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4428 - accuracy: 0.8637\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4368 - accuracy: 0.8649\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4297 - accuracy: 0.8658\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4324 - accuracy: 0.8670\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4298 - accuracy: 0.8670\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4261 - accuracy: 0.8685\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4230 - accuracy: 0.8684\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4212 - accuracy: 0.8702\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4156 - accuracy: 0.8720\n",
            "458/458 [==============================] - 2s 3ms/step - loss: 0.3204 - accuracy: 0.9055\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 2.2563 - accuracy: 0.1868\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 2.0091 - accuracy: 0.2843\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.0259 - accuracy: 0.6633\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.7774 - accuracy: 0.7502\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6869 - accuracy: 0.7825\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.6345 - accuracy: 0.8006\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.6052 - accuracy: 0.8104\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5828 - accuracy: 0.8180\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5607 - accuracy: 0.8229\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5398 - accuracy: 0.8323\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5286 - accuracy: 0.8333\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5134 - accuracy: 0.8399\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.5105 - accuracy: 0.8403\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4979 - accuracy: 0.8455\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4913 - accuracy: 0.8469\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4772 - accuracy: 0.8516\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4742 - accuracy: 0.8532\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4656 - accuracy: 0.8567\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4634 - accuracy: 0.8568\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4533 - accuracy: 0.8607\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4517 - accuracy: 0.8596\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4490 - accuracy: 0.8611\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4431 - accuracy: 0.8622\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4400 - accuracy: 0.8639\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4369 - accuracy: 0.8655\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4331 - accuracy: 0.8679\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4298 - accuracy: 0.8674\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4281 - accuracy: 0.8670\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4263 - accuracy: 0.8693\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4237 - accuracy: 0.8699\n",
            "458/458 [==============================] - 2s 3ms/step - loss: 0.2975 - accuracy: 0.9152\n",
            "Model evaluation  [0.29751813411712646, 0.9151594042778015]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un accuracy de 90 puede ser considerado como plausible dependiendo de la tarea que se le asigne. De igual manera, la raz√≥n entre la desviaci√≥n est√°ndar de la media apuntan a que dicho accuracy posee una estabilidad sustancial (<1%)."
      ],
      "metadata": {
        "id": "UqLrzQGjGEhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(k_eval)\n",
        "print(\"Mean accuracy: \", result.mean())\n",
        "print(\"Standard deviation: \", result.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUUEIboYKyDo",
        "outputId": "3b7741ef-dbf8-499f-aa96-02bec1c6003c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy:  0.9082136034965516\n",
            "Standard deviation:  0.004157153818691504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se muestan los resultados sobre el set de prueba provisto por el dataset. Es notable que tuvo un accuracy sustancialmente m√°s alto que el promedio del KFold. Esto puede deberse a la capa de data augmentation que altera las im√°genes para prevenir overfitting sobre el set de entrenamiento, pero que resulta ben√©fico para su desempe√±o en datos no vistos previamente."
      ],
      "metadata": {
        "id": "UkIBwHgNHJH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = m1.evaluate(x=test_images, y=test_labels, verbose=0)\n",
        "\n",
        "print('Test accuracy is: {:0.4f} \\nTest loss is: {:0.4f}'.\n",
        "      format(test_acc, test_loss))"
      ],
      "metadata": {
        "id": "_8yGk8oT08qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425ea771-fd47-48ee-84e5-4322159bffd4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is: 0.9002 \n",
            "Test loss is: 0.3368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segundo modelo (posibles mejoras)\n",
        "\n",
        "### Hacer la red m√°s profunda\n",
        "\n",
        "El primer modelo consta de 6 capas de convolusi√≥n, 3 con un tama√±o de output de 32 y 3 de tama√±o de 64. Entonces, una primera propuesta es hacer la red m√°s profunda agregando otras tres capas de convolusi√≥n con tama√±o de output mayor (128), para que se mantenga la complejidad de las capas intermedias. (densidad de output intermedio). Esto implica tener m√°s par√°metros para interpretar diferencias m√°s sutiles.\n",
        "\n",
        "### Agregar skip connections\n",
        "\n",
        "Al hacer la red m√°s profunda nos podemos encontrar con problemas de variabilidad no deseada en el gradiente de la funci√≥n de costo (shattered gradient), por lo que conexiones residuales pueden ayudar a aminorar este fen√≥meno.\n",
        "\n",
        "### Agregar una capa densa al final\n",
        "\n",
        "Aunque es posible que una red densa provoque overfitting al aprender las caracter√≠sticas proporcionadas por las CNN, podr√≠a ser √∫til para mejorar el accuracy un poco m√°s en caso de que la CNN por s√≠ sola no alcance resultados deseados.\n",
        "\n",
        "### Alinear Max-Pooling con la red que incrementa el n√∫mero de kernels\n",
        "\n",
        "Aunque el beneficio no sea asegurado, se puede interpretar como la multiplicaci√≥n del n√∫mero de celdas que un kernel \"ve\" en cada uno de los inputs y el n√∫mero de kernel per se. Si se mantiene el n√∫mero de kernels despu√©s de un Max Pooling, dichos kernels ver√°n una simplificaci√≥n de los inputs anteriores y probablemente carezcan de informaci√≥n valiosa, y esto se propagar√° a las capas siguientes. Esto asume que la informaci√≥n perdida por el Max Pooling en efecto es significativa, pero se sigue tomando las ventajas del pooling aplic√°ndolo en un momento m√°s oportuno.\n"
      ],
      "metadata": {
        "id": "HkKTPxfqIAiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bC3kSRUTmKo7"
      },
      "outputs": [],
      "source": [
        "def M2():    \n",
        "    input = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "    data_augmentation = keras.Sequential(\n",
        "        [\n",
        "            layers.RandomRotation(0.2),\n",
        "            layers.RandomZoom(0.2),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    x = data_augmentation(input)\n",
        "\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "    for size in [32, 64, 128]:\n",
        "        residual = x\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "        x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "        \n",
        "\n",
        "        residual = layers.Conv2D(\n",
        "            size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "\n",
        "        x = layers.add([x, residual])\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "    model2 = keras.Model(inputs=input, outputs=outputs)\n",
        "    return model2\n",
        "\n",
        "model2 = M2()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al tratarse de una red algo m√°s profunda, se reducir√° un poco el learning rate respecto al anterior para aminorar un posible fen√≥mento de exploding gradient."
      ],
      "metadata": {
        "id": "IFUqj81YYkDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vUPHuUW8muCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bca1a9-d003-4fc2-89b7-292367981d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
        "optimizer = keras.optimizers.Adam(lr=.0008, amsgrad=True)\n",
        "model2.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H_wVQEWm2Vi",
        "outputId": "584113be-3157-4d41-eb70-3218cc866df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "487/487 [==============================] - 14s 26ms/step - loss: 2.2382 - accuracy: 0.1939 - val_loss: 1.8839 - val_accuracy: 0.3352\n",
            "Epoch 2/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 1.2304 - accuracy: 0.5842 - val_loss: 0.5994 - val_accuracy: 0.8114\n",
            "Epoch 3/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.6948 - accuracy: 0.7756 - val_loss: 0.4943 - val_accuracy: 0.8438\n",
            "Epoch 4/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.5620 - accuracy: 0.8201 - val_loss: 0.3786 - val_accuracy: 0.8843\n",
            "Epoch 5/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.4983 - accuracy: 0.8443 - val_loss: 0.3604 - val_accuracy: 0.8907\n",
            "Epoch 6/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.4608 - accuracy: 0.8564 - val_loss: 0.3346 - val_accuracy: 0.8984\n",
            "Epoch 7/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.4326 - accuracy: 0.8660 - val_loss: 0.3095 - val_accuracy: 0.9078\n",
            "Epoch 8/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.4140 - accuracy: 0.8711 - val_loss: 0.3085 - val_accuracy: 0.9089\n",
            "Epoch 9/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3932 - accuracy: 0.8786 - val_loss: 0.2798 - val_accuracy: 0.9161\n",
            "Epoch 10/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3773 - accuracy: 0.8833 - val_loss: 0.2818 - val_accuracy: 0.9179\n",
            "Epoch 11/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3691 - accuracy: 0.8867 - val_loss: 0.2784 - val_accuracy: 0.9150\n",
            "Epoch 12/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3544 - accuracy: 0.8902 - val_loss: 0.2596 - val_accuracy: 0.9230\n",
            "Epoch 13/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3470 - accuracy: 0.8930 - val_loss: 0.2813 - val_accuracy: 0.9166\n",
            "Epoch 14/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3399 - accuracy: 0.8961 - val_loss: 0.2590 - val_accuracy: 0.9220\n",
            "Epoch 15/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3325 - accuracy: 0.8987 - val_loss: 0.2546 - val_accuracy: 0.9234\n",
            "Epoch 16/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3268 - accuracy: 0.9001 - val_loss: 0.2553 - val_accuracy: 0.9249\n",
            "Epoch 17/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3177 - accuracy: 0.9029 - val_loss: 0.2614 - val_accuracy: 0.9232\n",
            "Epoch 18/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3113 - accuracy: 0.9042 - val_loss: 0.2395 - val_accuracy: 0.9284\n",
            "Epoch 19/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3146 - accuracy: 0.9034 - val_loss: 0.2402 - val_accuracy: 0.9291\n",
            "Epoch 20/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3059 - accuracy: 0.9056 - val_loss: 0.2382 - val_accuracy: 0.9307\n",
            "Epoch 21/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3032 - accuracy: 0.9070 - val_loss: 0.2305 - val_accuracy: 0.9325\n",
            "Epoch 22/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2968 - accuracy: 0.9100 - val_loss: 0.2387 - val_accuracy: 0.9301\n",
            "Epoch 23/40\n",
            "487/487 [==============================] - 12s 26ms/step - loss: 0.2892 - accuracy: 0.9111 - val_loss: 0.2330 - val_accuracy: 0.9328\n",
            "Epoch 24/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2865 - accuracy: 0.9128 - val_loss: 0.2292 - val_accuracy: 0.9364\n",
            "Epoch 25/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2834 - accuracy: 0.9138 - val_loss: 0.2299 - val_accuracy: 0.9338\n",
            "Epoch 26/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2823 - accuracy: 0.9145 - val_loss: 0.2263 - val_accuracy: 0.9322\n",
            "Epoch 27/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2781 - accuracy: 0.9154 - val_loss: 0.2190 - val_accuracy: 0.9363\n",
            "Epoch 28/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2748 - accuracy: 0.9163 - val_loss: 0.2408 - val_accuracy: 0.9316\n",
            "Epoch 29/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2745 - accuracy: 0.9173 - val_loss: 0.2192 - val_accuracy: 0.9368\n",
            "Epoch 30/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2696 - accuracy: 0.9182 - val_loss: 0.2217 - val_accuracy: 0.9370\n",
            "Epoch 31/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2685 - accuracy: 0.9188 - val_loss: 0.2223 - val_accuracy: 0.9369\n",
            "Epoch 32/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2655 - accuracy: 0.9201 - val_loss: 0.2212 - val_accuracy: 0.9361\n",
            "Epoch 33/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2641 - accuracy: 0.9209 - val_loss: 0.2239 - val_accuracy: 0.9356\n",
            "Epoch 34/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2609 - accuracy: 0.9215 - val_loss: 0.2247 - val_accuracy: 0.9343\n",
            "Epoch 35/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2607 - accuracy: 0.9212 - val_loss: 0.2142 - val_accuracy: 0.9378\n",
            "Epoch 36/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2559 - accuracy: 0.9212 - val_loss: 0.2159 - val_accuracy: 0.9383\n",
            "Epoch 37/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2524 - accuracy: 0.9236 - val_loss: 0.2229 - val_accuracy: 0.9356\n",
            "Epoch 38/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2508 - accuracy: 0.9242 - val_loss: 0.2157 - val_accuracy: 0.9350\n",
            "Epoch 39/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2497 - accuracy: 0.9253 - val_loss: 0.2168 - val_accuracy: 0.9375\n",
            "Epoch 40/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2464 - accuracy: 0.9262 - val_loss: 0.2132 - val_accuracy: 0.9399\n"
          ]
        }
      ],
      "source": [
        "history2 = model2.fit(X_train, y_train, batch_size=128, \n",
        "                      epochs=40, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuod83Yz-CsL",
        "outputId": "dd80711f-6598-479c-a0c8-58aa463242e8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " sequential_7 (Sequential)      (None, 32, 32, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['sequential_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 32, 32, 3)   12          ['rescaling[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 32, 32, 32)   864         ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 32)   0           ['conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 32, 32, 32)   0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 32, 32, 32)   9216        ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 32)   0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 32, 32, 32)  128         ['activation_1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 32, 32, 32)   9216        ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 32)   0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_18 (MaxPooling2D  (None, 16, 16, 32)  0           ['activation_2[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 16, 16, 32)   0           ['max_pooling2d_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 32)   96          ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 32)   0           ['dropout_19[0][0]',             \n",
            "                                                                  'conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 32)  128         ['add[0][0]']                    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 16, 16, 64)   18432       ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 64)   0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 16, 16, 64)   0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 16, 16, 64)   36864       ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 64)   0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  256         ['activation_4[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 16, 16, 64)   36864       ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_19 (MaxPooling2D  (None, 8, 8, 64)    0           ['activation_5[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 8, 8, 64)     0           ['max_pooling2d_19[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 8, 8, 64)     2048        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8, 8, 64)     0           ['dropout_21[0][0]',             \n",
            "                                                                  'conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 8, 8, 64)    256         ['add_1[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 8, 8, 128)    73728       ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8, 8, 128)    0           ['conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 8, 8, 128)    0           ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 8, 8, 128)    147456      ['dropout_22[0][0]']             \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 8, 8, 128)    0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 8, 8, 128)   512         ['activation_7[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 8, 8, 128)    147456      ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 8, 8, 128)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooling2D  (None, 4, 4, 128)   0           ['activation_8[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 4, 4, 128)    0           ['max_pooling2d_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 4, 4, 128)    8192        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 4, 4, 128)    0           ['dropout_23[0][0]',             \n",
            "                                                                  'conv2d_47[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 4, 4, 128)   512         ['add_2[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 2048)         0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          524544      ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 10)           2570        ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,019,350\n",
            "Trainable params: 1,018,448\n",
            "Non-trainable params: 902\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No se observa underfitting u overfitting al igual que en el primer modelo (no se separan las l√≠neas). No obstante, los valores de accuracy tanto de entrenamiento como validaci√≥n son superiores. Incluso la separaci√≥n entre √©stas es menor. Esto indica un \"fit\" superior. Adem√°s, el accuracy de validaci√≥n se estabiliza m√°s r√°pido que en la primera arquitectura."
      ],
      "metadata": {
        "id": "KDMoLWiGcpBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = history2.history['accuracy']\n",
        "val_acc = history2.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Epochs vs. Training and Validation Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "idF_8vR-ciuT",
        "outputId": "247367a9-ec2b-4513-c974-ebe6fed7172b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Epochs vs. Training and Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n\n",
        "\n",
        "Se proceder√° a realizar la mismo procedimiento de KFold cross-validation que el modelo anterior. (k=5)"
      ],
      "metadata": {
        "id": "mryosiRXY5Dq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1De5B4mCGY6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f602e574-a526-4ce3-90f7-765ab0e7c63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 2.0194 - accuracy: 0.2699\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.8311 - accuracy: 0.7285\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.5993 - accuracy: 0.8096\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.5223 - accuracy: 0.8331\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4821 - accuracy: 0.8504\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.4525 - accuracy: 0.8580\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4322 - accuracy: 0.8666\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4130 - accuracy: 0.8726\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4004 - accuracy: 0.8773\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3885 - accuracy: 0.8808\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3794 - accuracy: 0.8827\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3707 - accuracy: 0.8847\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3612 - accuracy: 0.8891\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3539 - accuracy: 0.8909\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3502 - accuracy: 0.8926\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3394 - accuracy: 0.8959\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 0.3290 - accuracy: 0.8996\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3248 - accuracy: 0.9010\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3270 - accuracy: 0.8991\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3177 - accuracy: 0.9027\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3163 - accuracy: 0.9033\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3154 - accuracy: 0.9030\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3085 - accuracy: 0.9054\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3045 - accuracy: 0.9080\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3024 - accuracy: 0.9078\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2996 - accuracy: 0.9084\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2968 - accuracy: 0.9101\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2926 - accuracy: 0.9097\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2901 - accuracy: 0.9113\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2904 - accuracy: 0.9122\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2290 - accuracy: 0.9360\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 1.8138 - accuracy: 0.3560\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.7592 - accuracy: 0.7540\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5820 - accuracy: 0.8156\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5122 - accuracy: 0.8377\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 0.4763 - accuracy: 0.8512\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4485 - accuracy: 0.8603\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4276 - accuracy: 0.8677\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4074 - accuracy: 0.8741\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3961 - accuracy: 0.8769\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3826 - accuracy: 0.8823\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3756 - accuracy: 0.8855\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3644 - accuracy: 0.8879\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3583 - accuracy: 0.8911\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3511 - accuracy: 0.8933\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 0.3480 - accuracy: 0.8939\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3405 - accuracy: 0.8961\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3342 - accuracy: 0.8986\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3308 - accuracy: 0.8986\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3284 - accuracy: 0.8997\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3215 - accuracy: 0.9020\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3197 - accuracy: 0.9021\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3137 - accuracy: 0.9048\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3072 - accuracy: 0.9062\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3041 - accuracy: 0.9080\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3033 - accuracy: 0.9090\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2991 - accuracy: 0.9078\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2953 - accuracy: 0.9100\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2923 - accuracy: 0.9116\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2917 - accuracy: 0.9127\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2865 - accuracy: 0.9137\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2257 - accuracy: 0.9351\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 2.0764 - accuracy: 0.2462\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.8665 - accuracy: 0.7174\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.6037 - accuracy: 0.8079\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.5290 - accuracy: 0.8335\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4907 - accuracy: 0.8465\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4566 - accuracy: 0.8589\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.4366 - accuracy: 0.8650\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4155 - accuracy: 0.8705\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4035 - accuracy: 0.8758\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3938 - accuracy: 0.8790\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3759 - accuracy: 0.8847\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3719 - accuracy: 0.8854\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3642 - accuracy: 0.8869\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3562 - accuracy: 0.8904\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3449 - accuracy: 0.8946\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3400 - accuracy: 0.8952\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3379 - accuracy: 0.8976\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3317 - accuracy: 0.8979\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3293 - accuracy: 0.8992\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3242 - accuracy: 0.9019\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3143 - accuracy: 0.9035\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3135 - accuracy: 0.9046\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3105 - accuracy: 0.9052\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3045 - accuracy: 0.9065\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3059 - accuracy: 0.9069\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2978 - accuracy: 0.9096\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2993 - accuracy: 0.9087\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2921 - accuracy: 0.9104\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2915 - accuracy: 0.9117\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2898 - accuracy: 0.9122\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2450 - accuracy: 0.9339\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 20s 10ms/step - loss: 2.1557 - accuracy: 0.2191\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.9447 - accuracy: 0.6877\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.6236 - accuracy: 0.8012\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.5331 - accuracy: 0.8312\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.4889 - accuracy: 0.8471\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4612 - accuracy: 0.8568\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4369 - accuracy: 0.8646\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4211 - accuracy: 0.8688\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4023 - accuracy: 0.8748\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3875 - accuracy: 0.8805\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3754 - accuracy: 0.8840\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3691 - accuracy: 0.8863\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3637 - accuracy: 0.8880\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3549 - accuracy: 0.8919\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3481 - accuracy: 0.8924\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3440 - accuracy: 0.8949\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3388 - accuracy: 0.8965\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3320 - accuracy: 0.8981\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3240 - accuracy: 0.9013\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3234 - accuracy: 0.9006\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3187 - accuracy: 0.9026\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3144 - accuracy: 0.9019\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3119 - accuracy: 0.9053\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3084 - accuracy: 0.9054\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3024 - accuracy: 0.9066\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2984 - accuracy: 0.9090\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2970 - accuracy: 0.9091\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2972 - accuracy: 0.9092\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2927 - accuracy: 0.9112\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2935 - accuracy: 0.9101\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.2418 - accuracy: 0.9309\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 2.0522 - accuracy: 0.2600\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.9039 - accuracy: 0.7028\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.6201 - accuracy: 0.8026\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5361 - accuracy: 0.8305\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4897 - accuracy: 0.8486\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.4570 - accuracy: 0.8583\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4378 - accuracy: 0.8646\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4189 - accuracy: 0.8715\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4086 - accuracy: 0.8747\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3883 - accuracy: 0.8796\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3791 - accuracy: 0.8829\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3740 - accuracy: 0.8845\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3641 - accuracy: 0.8880\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3576 - accuracy: 0.8899\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3510 - accuracy: 0.8919\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3464 - accuracy: 0.8935\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3405 - accuracy: 0.8951\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3354 - accuracy: 0.8971\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3262 - accuracy: 0.9008\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3240 - accuracy: 0.9015\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3202 - accuracy: 0.9024\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.3183 - accuracy: 0.9030\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3138 - accuracy: 0.9047\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3085 - accuracy: 0.9053\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.3069 - accuracy: 0.9064\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3003 - accuracy: 0.9093\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2951 - accuracy: 0.9111\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.2947 - accuracy: 0.9115\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 17s 10ms/step - loss: 0.2914 - accuracy: 0.9116\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2895 - accuracy: 0.9108\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2182 - accuracy: 0.9375\n",
            "Model evaluation  [0.21819119155406952, 0.9374786615371704]\n"
          ]
        }
      ],
      "source": [
        "n_split = 5\n",
        "k_eval = []\n",
        "\n",
        "for train_i ,val_i in KFold(n_split).split(train_images):\n",
        "  x_train,x_val= train_images[train_i], train_images[val_i]\n",
        "  y_t,y_v= train_labels[train_i], train_labels[val_i]\n",
        "\n",
        "  aux = M2()\n",
        "\n",
        "  aux.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  aux.fit(x_train, y_t,epochs=30)\n",
        "\n",
        "  eval = aux.evaluate(x_val,y_v)\n",
        "  k_eval.append(eval[1])\n",
        "\n",
        "print('Model evaluation ', eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo que implementa las sugerencias present√≥ un incremento de .03 apr√≥ximadamente y mantuvo una relaci√≥n con la desviaci√≥n est√°ndar similar al primer modelo (<1%). Esto es una mejora significativa."
      ],
      "metadata": {
        "id": "yZPhrhfnZa1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(k_eval)\n",
        "print(\"Mean accuracy: \", result.mean())\n",
        "print(\"Standard deviation: \", result.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqK6zGZxf2l_",
        "outputId": "1cc27eeb-f199-403c-b485-f56885570d60"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy:  0.9346819877624511\n",
            "Standard deviation:  0.002219978995536582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente se muestra el desempe√±o de la versi√≥n entrenada por 40 √©pocas sobre el set de prueba. El accuracy increment√≥ .03 aproximadamente , aunque no fue la misma magnitud incremental que en los set de validaci√≥n, a√∫n fue una mejora significativa. Se tendr√≠a tambi√©n que evaluar ambos modelos al entrenarse en todav√≠a m√°s √©pocas para conocer su convergencia."
      ],
      "metadata": {
        "id": "t0nSxNM6agEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model2.evaluate(x=test_images, y=test_labels, verbose=0)\n",
        "\n",
        "print('Test accuracy is: {:0.4f} \\nTest loss is: {:0.4f}'.\n",
        "      format(test_acc, test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjuz9c2kuOQY",
        "outputId": "8b5ee0b1-fd5f-476d-8822-88ab5a4c76b6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is: 0.9469 \n",
            "Test loss is: 0.1926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicciones\n",
        "\n",
        "Se define una breve funci√≥n para visualizar las predicciones del modelo."
      ],
      "metadata": {
        "id": "XV9DheOtjGr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def m2_predict(index):\n",
        "    plt.imshow(test_images[index])\n",
        "    plt.show()\n",
        "\n",
        "    print('Label: ', (np.argmax(test_labels[index]) + 1) % 10)\n",
        "    print('Predicted label: ', (np.argmax(model2.predict(test_images[index].reshape((1,32,32,3)))) + 1) % 10)"
      ],
      "metadata": {
        "id": "lq53XDqBiz4J"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2_predict(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "aK6OoL5a8HUx",
        "outputId": "213b3181-dc6a-4af2-927a-4e75489ee869"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  7\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted label:  7\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}