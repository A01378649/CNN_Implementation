{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementaci√≥n de un modelo de Deep Learning"
      ],
      "metadata": {
        "id": "WzxVclfYof0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRa53RpC036s",
        "outputId": "ca7585b5-b4c4-4f50-8eaf-874c7bc6e141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/IA\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#%cd \"/content/drive/MyDrive/IA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "6IrEnA88Dfdc",
        "outputId": "c0516fb4-5d75-4a81-d68a-b57997b733cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85e36a6e-4893-4f5b-91b7-872e7257f49f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85e36a6e-4893-4f5b-91b7-872e7257f49f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (4).json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"a01378649\",\"key\":\"1dca8bf62fee4ec115bdb3be7cbe32ca\"}'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7__eIp5JS8N"
      },
      "outputs": [],
      "source": [
        "!rm -rf ~/.kaggle "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6YE08NGHQLD"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a1HpTU6HgMR",
        "outputId": "03ceecd3-cee0-4d89-999d-501588c472ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ref                                                             title                                            size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  ----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "akshaydattatraykhare/diabetes-dataset                           Diabetes Dataset                                  9KB  2022-10-06 08:55:25          10952        347  1.0              \n",
            "whenamancodes/covid-19-coronavirus-pandemic-dataset             COVID -19 Coronavirus Pandemic Dataset           11KB  2022-09-30 04:05:11           8720        281  1.0              \n",
            "stetsondone/video-game-sales-by-genre                           Video Game Sales by Genre                        12KB  2022-10-31 17:56:01            760         23  1.0              \n",
            "whenamancodes/credit-card-customers-prediction                  Credit Card Customers Prediction                379KB  2022-10-30 13:03:27           1315         40  1.0              \n",
            "whenamancodes/students-performance-in-exams                     Students Performance in Exams                     9KB  2022-09-14 15:14:54          15145        283  1.0              \n",
            "akshaydattatraykhare/data-for-admission-in-the-university       Data for Admission in the University              4KB  2022-10-27 11:05:45           1848         43  1.0              \n",
            "michaelbryantds/electric-vehicle-charging-dataset               Electric Vehicle Charging Dataset                98KB  2022-11-02 01:45:23            629         32  0.9411765        \n",
            "maharshipandya/-spotify-tracks-dataset                          üéπ Spotify Tracks Dataset                          8MB  2022-10-22 14:40:15           2174         71  1.0              \n",
            "hasibalmuzdadid/global-air-pollution-dataset                    Global Air Pollution Dataset                    371KB  2022-11-08 14:43:32           1094         42  1.0              \n",
            "whenamancodes/amazon-reviews-on-women-dresses                   Amazon Reviews on Women Dresses                   3MB  2022-10-29 12:47:06            501         32  1.0              \n",
            "akshaydattatraykhare/car-details-dataset                        Car Details Dataset                              56KB  2022-10-21 06:11:56           2643         44  1.0              \n",
            "whenamancodes/international-football-from-1872-to-2022          International Football from 1872 to 2022        572KB  2022-10-30 13:27:29            632         28  0.9411765        \n",
            "whenamancodes/customer-personality-analysis                     Company's Ideal Customers | Marketing Strategy   62KB  2022-10-30 14:17:42            887         31  1.0              \n",
            "dimitryzub/walmart-coffee-listings-from-500-stores              Walmart Coffee Listings from 500 stores          85KB  2022-10-25 09:20:12           1259         40  1.0              \n",
            "dheerajmukati/most-runs-in-cricket                              Most Runs in International cricket                4KB  2022-10-16 16:49:20            677         31  1.0              \n",
            "thedevastator/food-prices-year-by-year                          Global Food Prices Year By Year                   7KB  2022-10-30 08:49:55            889         31  1.0              \n",
            "saikumartamminana/gold-price-prediction                         Gold Price Prediction                            41KB  2022-10-30 19:07:30            946         24  0.8235294        \n",
            "thedevastator/udemy-courses-revenue-generation-and-course-anal  Udemy Courses                                   429KB  2022-10-17 00:11:53           1892         57  1.0              \n",
            "whenamancodes/adidas-us-retail-products-dataset                 Adidas US Retail Products Dataset               286KB  2022-10-26 15:44:20            710         33  1.0              \n",
            "jainilcoder/online-payment-fraud-detection                      Online Payment Fraud Detection                  178MB  2022-10-26 12:35:46           1035         38  0.9705882        \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecci√≥n de dataset\n",
        "\n",
        "Se escoger√° la base de SVHN que contiene im√°genes RGB de n√∫meros en diferentes lugares del mundo real. Asimismo, existe ruido alrededor como parte del ambiente, o incluso otros n√∫meros. En este caso, solo nos interesa categorizar el n√∫mero m√°s centrado."
      ],
      "metadata": {
        "id": "cB51Hil1pFgK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoaxJc5JHhm1",
        "outputId": "ea3af18d-4cf1-41a3-eaea-dbeec5045a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "svhndataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d quanbk/svhndataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psCD7RgMKZ0S",
        "outputId": "2bfe1f59-e29d-47fe-c1e8-a63b87925b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  svhndataset.zip\n",
            "replace extra_32x32.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test_32x32.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train_32x32.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "!unzip svhndataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cDn4LUBcLODy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La base de datos incluye por defecto el set de entrenamiento y prueba, no obstante, hace falta alinear los datos para ser consumidos por el modelo. (Formatear a NHWC)"
      ],
      "metadata": {
        "id": "8E_d5evcqewu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ISrO0TLy6p",
        "outputId": "19933684-7a53-4a85-9196-e2c29b688606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3, 73257)\n",
            "(32, 32, 3, 26032)\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "\n",
        "train_raw = loadmat('train_32x32.mat')\n",
        "test_raw = loadmat('test_32x32.mat')\n",
        "\n",
        "train_images = np.array(train_raw['X'])\n",
        "test_images = np.array(test_raw['X'])\n",
        "train_labels = train_raw['y']\n",
        "test_labels = test_raw['y']\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FckzIleXMrlO",
        "outputId": "91a49903-3f5c-4940-be1e-878e2b01d6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(73257, 32, 32, 3)\n",
            "(26032, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "train_images = np.moveaxis(train_images, -1, 0)\n",
        "test_images = np.moveaxis(test_images, -1, 0)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como anteriormente se explica, aunque existan dos n√∫meros, el label provisto solo hace referencia al n√∫mero del centro."
      ],
      "metadata": {
        "id": "kVDKToQJfsFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "KsR_bg7LOPMi",
        "outputId": "bd032e37-a6b4-4bed-d485-31ee5b4d1b14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  [3]\n"
          ]
        }
      ],
      "source": [
        "#Probando que las im√°genes se hayan cargado de manera correcta\n",
        "plt.imshow(train_images[8])\n",
        "plt.show()\n",
        "\n",
        "print('Label: ', train_labels[8])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utilizar√° One-Hot Encoding para representar las categor√≠as (0 al 9)"
      ],
      "metadata": {
        "id": "AyXvAenYrNcj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ERDX_jTDPBMH"
      },
      "outputs": [],
      "source": [
        "lb = LabelBinarizer()\n",
        "train_labels = lb.fit_transform(train_labels)\n",
        "test_labels = lb.fit_transform(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos el set de entrenamiento inicial para crear el split de entrenamiento y validaci√≥n para el modelo. (85% y 15% respectivamente)"
      ],
      "metadata": {
        "id": "axV4QekIsIBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6lW5FkLiPTkB"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels,\n",
        "                                                  test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto confirmamos el n√∫mero y dimensiones para los conjuntos de entrenamiento y validaci√≥n."
      ],
      "metadata": {
        "id": "CzyfCPnBsCz0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVHIZ6EuPoW9",
        "outputId": "2a6d19e0-d117-4aad-96e4-de012dce1352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(62268, 32, 32, 3)\n",
            "(10989, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para incrementar el dominio de la naturaleza de las im√°genes, a√±adiremos una capa de data augmentation para prevenir overfitting. Cabe destacar que solo se aplica rotaci√≥n y zoom aleatorios para no cambiar efectivamente la categor√≠a de la imagen. Por ejemplo, no se le pone random flip porque el n√∫mero dejar√≠a de ser reconocible."
      ],
      "metadata": {
        "id": "zhItNXyOuJQT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3oYsDF3ePxPh"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomRotation(0.2),\n",
        "        layers.RandomZoom(0.2)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definici√≥n del modelo\n",
        "\n",
        "Se opt√≥ por el uso de una CNN tradicional de seis capas principales de convoluci√≥n. Se utiliza BatchNormalization para establizar el comportamiento durante el entrenamiento. Adem√°s, Se utilizan capas de MaxPooling intermedias para realizar downsampling y agilizar el c√≥mputo de predicciones, de igual manera, sirve para atenuar varianzas en la imagen como rotaci√≥n o el zoom que puede suceder naturalmente. Igualmente, se a√±aden capas de Dropout para prevenir overfitting. \n",
        "\n",
        "Finalmente, los datos procesados son utilizados por una capa de softmax que predice la categor√≠a."
      ],
      "metadata": {
        "id": "WT2u6zypu1vK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e0gdumKVQeWh"
      },
      "outputs": [],
      "source": [
        "#Se define una funci√≥n que regresa la arquitectura en limpio cada vez que se llama\n",
        "def Model1():\n",
        "    return keras.Sequential([\n",
        "    data_augmentation,\n",
        "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
        "                           activation='relu',\n",
        "                           input_shape=(32, 32, 3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
        "                        activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    \n",
        "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
        "                           activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same',\n",
        "                        activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same', \n",
        "                           activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same',\n",
        "                        activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10,  activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No se utiliz√≥ ninguna t√©cnica en especial para determinar el mejor learning rate (hyperparameter tunning), no obstante se sabe que para las CNN √©ste tiene que ser particularmente bajo, por lo que se decidi√≥ establecerlo como 0.001."
      ],
      "metadata": {
        "id": "PQJt-hs7C6dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = Model1()\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
        "optimizer = keras.optimizers.Adam(lr=0.001, amsgrad=True)\n",
        "m1.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjqSpzhH0EKP",
        "outputId": "62010786-3895-40fb-d1b2-ed1e01824ff3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "cyIfAGRYhaX1",
        "outputId": "9c8c8d09-a7a7-45d4-f22b-f140a17a20eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7c827c042d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2870\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m           'the model on a batch of data.')\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ],
      "source": [
        "m1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4nN6VbCdC3zR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB4Xh8vNilev",
        "outputId": "5e109389-1d82-41cd-bddd-e981eee142a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "487/487 [==============================] - 17s 15ms/step - loss: 2.2285 - accuracy: 0.2094 - val_loss: 1.7491 - val_accuracy: 0.3601\n",
            "Epoch 2/40\n",
            "487/487 [==============================] - 6s 13ms/step - loss: 1.1380 - accuracy: 0.6218 - val_loss: 0.6548 - val_accuracy: 0.7926\n",
            "Epoch 3/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.7647 - accuracy: 0.7538 - val_loss: 0.5491 - val_accuracy: 0.8267\n",
            "Epoch 4/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.6644 - accuracy: 0.7887 - val_loss: 0.4455 - val_accuracy: 0.8661\n",
            "Epoch 5/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.6148 - accuracy: 0.8045 - val_loss: 0.4458 - val_accuracy: 0.8647\n",
            "Epoch 6/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5772 - accuracy: 0.8169 - val_loss: 0.4598 - val_accuracy: 0.8589\n",
            "Epoch 7/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.5525 - accuracy: 0.8259 - val_loss: 0.3869 - val_accuracy: 0.8809\n",
            "Epoch 8/40\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5331 - accuracy: 0.8313 - val_loss: 0.4353 - val_accuracy: 0.8634\n",
            "Epoch 9/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5209 - accuracy: 0.8376 - val_loss: 0.3786 - val_accuracy: 0.8822\n",
            "Epoch 10/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5041 - accuracy: 0.8428 - val_loss: 0.3810 - val_accuracy: 0.8837\n",
            "Epoch 11/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4922 - accuracy: 0.8447 - val_loss: 0.4249 - val_accuracy: 0.8693\n",
            "Epoch 12/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4841 - accuracy: 0.8486 - val_loss: 0.3452 - val_accuracy: 0.8919\n",
            "Epoch 13/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4759 - accuracy: 0.8505 - val_loss: 0.3505 - val_accuracy: 0.8932\n",
            "Epoch 14/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4658 - accuracy: 0.8540 - val_loss: 0.4370 - val_accuracy: 0.8625\n",
            "Epoch 15/40\n",
            "487/487 [==============================] - 6s 13ms/step - loss: 0.4598 - accuracy: 0.8581 - val_loss: 0.3379 - val_accuracy: 0.8977\n",
            "Epoch 16/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4558 - accuracy: 0.8592 - val_loss: 0.3323 - val_accuracy: 0.8993\n",
            "Epoch 17/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4535 - accuracy: 0.8595 - val_loss: 0.3911 - val_accuracy: 0.8808\n",
            "Epoch 18/40\n",
            "487/487 [==============================] - 6s 13ms/step - loss: 0.4439 - accuracy: 0.8623 - val_loss: 0.2981 - val_accuracy: 0.9117\n",
            "Epoch 19/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4393 - accuracy: 0.8635 - val_loss: 0.3058 - val_accuracy: 0.9094\n",
            "Epoch 20/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4348 - accuracy: 0.8646 - val_loss: 0.3146 - val_accuracy: 0.9064\n",
            "Epoch 21/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4325 - accuracy: 0.8662 - val_loss: 0.3215 - val_accuracy: 0.9034\n",
            "Epoch 22/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4265 - accuracy: 0.8685 - val_loss: 0.2983 - val_accuracy: 0.9110\n",
            "Epoch 23/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4271 - accuracy: 0.8674 - val_loss: 0.2965 - val_accuracy: 0.9103\n",
            "Epoch 24/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4219 - accuracy: 0.8696 - val_loss: 0.2965 - val_accuracy: 0.9138\n",
            "Epoch 25/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4171 - accuracy: 0.8714 - val_loss: 0.3177 - val_accuracy: 0.9019\n",
            "Epoch 26/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4120 - accuracy: 0.8725 - val_loss: 0.2945 - val_accuracy: 0.9120\n",
            "Epoch 27/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.4095 - accuracy: 0.8744 - val_loss: 0.3129 - val_accuracy: 0.9078\n",
            "Epoch 28/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4088 - accuracy: 0.8737 - val_loss: 0.3174 - val_accuracy: 0.9057\n",
            "Epoch 29/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4067 - accuracy: 0.8749 - val_loss: 0.3098 - val_accuracy: 0.9072\n",
            "Epoch 30/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4015 - accuracy: 0.8755 - val_loss: 0.2906 - val_accuracy: 0.9140\n",
            "Epoch 31/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4019 - accuracy: 0.8761 - val_loss: 0.3379 - val_accuracy: 0.8974\n",
            "Epoch 32/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.4000 - accuracy: 0.8776 - val_loss: 0.3030 - val_accuracy: 0.9074\n",
            "Epoch 33/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.3950 - accuracy: 0.8778 - val_loss: 0.2880 - val_accuracy: 0.9137\n",
            "Epoch 34/40\n",
            "487/487 [==============================] - 6s 13ms/step - loss: 0.3914 - accuracy: 0.8794 - val_loss: 0.2918 - val_accuracy: 0.9139\n",
            "Epoch 35/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.3939 - accuracy: 0.8778 - val_loss: 0.2825 - val_accuracy: 0.9156\n",
            "Epoch 36/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.3878 - accuracy: 0.8804 - val_loss: 0.3139 - val_accuracy: 0.9080\n",
            "Epoch 37/40\n",
            "487/487 [==============================] - 8s 17ms/step - loss: 0.3906 - accuracy: 0.8803 - val_loss: 0.2867 - val_accuracy: 0.9163\n",
            "Epoch 38/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.3866 - accuracy: 0.8819 - val_loss: 0.2925 - val_accuracy: 0.9135\n",
            "Epoch 39/40\n",
            "487/487 [==============================] - 7s 13ms/step - loss: 0.3889 - accuracy: 0.8820 - val_loss: 0.2789 - val_accuracy: 0.9188\n",
            "Epoch 40/40\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.3832 - accuracy: 0.8813 - val_loss: 0.2677 - val_accuracy: 0.9211\n"
          ]
        }
      ],
      "source": [
        "history = m1.fit(X_train, y_train, batch_size=128,\n",
        "                              epochs=40, validation_data=(X_val, y_val),\n",
        "                              callbacks=[early_stopping]) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se muestra el accuracy del modelo, comparando su desempe√±o en el set de entrenamiento y validaci√≥n. En este caso, se observa que ambos tienen pendiente positiva en todo momento. No existe una disparidad sustancial en ambas magnitudes por lo que no se trata de underfitting u overfitting. Cabe destacar que el accuracy de entrenamiento es m√°s estable que el de validaci√≥n, pero el segundo se mantiene lo suficiente para mantener la tendencia. Inclusive se puede apreciar menos variabilidad en las √∫ltimas √©pocas."
      ],
      "metadata": {
        "id": "_Ht4kw8dDugo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Epochs vs. Training and Validation Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "wuw3unbX0iXt",
        "outputId": "38bc98a4-6f47-4c5a-9eeb-d6a0e8dda463"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Epochs vs. Training and Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n del modelo\n",
        "\n",
        "Para apreciar el comportamiento del modelo durante y al final del entrenamiento, se utilizar√° el KFold cross-validation para analizar su consistencia. Para ello, se determinar√° el accuracy promedio y su desviaci√≥n est√°ndar de todas las instancias experimentales. En este caso, tanto un accuracy promedio alto y una desviaci√≥n est√°ndar baja (qu√© tan entrenable es) apuntan a un modelo con mejor desempe√±o."
      ],
      "metadata": {
        "id": "qW8NrobU0-D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "PPfeDmKk2RIz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En contraste a la primera instancia del modelo, cada iteraci√≥n del KFold se entrener√°n solo durante 30 √©pocas."
      ],
      "metadata": {
        "id": "jg6QfWmnGKTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#80% train y 20% validation\n",
        "n_split = 5\n",
        "k_eval = []\n",
        "\n",
        "for train_i ,val_i in KFold(n_split).split(train_images):\n",
        "  x_train,x_val= train_images[train_i], train_images[val_i]\n",
        "  y_t,y_v= train_labels[train_i], train_labels[val_i]\n",
        "\n",
        "  aux = Model1()\n",
        "\n",
        "  aux.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  aux.fit(x_train, y_t,epochs=30)\n",
        "\n",
        "  eval = aux.evaluate(x_val,y_v)\n",
        "  k_eval.append(eval[1])\n",
        "\n",
        "print('Model evaluation ', eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTE3CkPk1_nM",
        "outputId": "f956d5b1-0662-4502-b7e7-31a0b6de28be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 17s 8ms/step - loss: 2.2206 - accuracy: 0.1986\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.2058 - accuracy: 0.5970\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.8142 - accuracy: 0.7380\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6989 - accuracy: 0.7742\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 0.6481 - accuracy: 0.7937\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6096 - accuracy: 0.8082\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5826 - accuracy: 0.8180\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5590 - accuracy: 0.8249\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5436 - accuracy: 0.8306\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5264 - accuracy: 0.8337\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5133 - accuracy: 0.8394\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5078 - accuracy: 0.8410\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5025 - accuracy: 0.8444\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4917 - accuracy: 0.8451\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 14s 8ms/step - loss: 0.4823 - accuracy: 0.8497\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4794 - accuracy: 0.8494\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4706 - accuracy: 0.8538\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4656 - accuracy: 0.8549\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 0.4608 - accuracy: 0.8571\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 17s 9ms/step - loss: 0.4554 - accuracy: 0.8579\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 0.4519 - accuracy: 0.8597\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4485 - accuracy: 0.8621\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4432 - accuracy: 0.8639\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4379 - accuracy: 0.8643\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 16s 9ms/step - loss: 0.4380 - accuracy: 0.8652\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4328 - accuracy: 0.8668\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4311 - accuracy: 0.8659\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4259 - accuracy: 0.8689\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4249 - accuracy: 0.8691\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4188 - accuracy: 0.8705\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2981 - accuracy: 0.9121\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 2.2561 - accuracy: 0.1860\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.6555 - accuracy: 0.4242\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.8912 - accuracy: 0.7095\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.7222 - accuracy: 0.7692\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6527 - accuracy: 0.7942\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.6104 - accuracy: 0.8087\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 0.5799 - accuracy: 0.8175\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5556 - accuracy: 0.8253\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5432 - accuracy: 0.8313\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5261 - accuracy: 0.8347\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.5129 - accuracy: 0.8396\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5049 - accuracy: 0.8426\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4955 - accuracy: 0.8447\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4837 - accuracy: 0.8479\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4790 - accuracy: 0.8510\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4708 - accuracy: 0.8530\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4658 - accuracy: 0.8557\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4615 - accuracy: 0.8572\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4582 - accuracy: 0.8582\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 0.4503 - accuracy: 0.8604\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4495 - accuracy: 0.8632\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4411 - accuracy: 0.8648\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4353 - accuracy: 0.8660\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4346 - accuracy: 0.8658\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4267 - accuracy: 0.8689\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4327 - accuracy: 0.8664\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4251 - accuracy: 0.8691\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4237 - accuracy: 0.8697\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4248 - accuracy: 0.8690\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4208 - accuracy: 0.8701\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.3295 - accuracy: 0.9005\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 2.2345 - accuracy: 0.1944\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.4720 - accuracy: 0.4985\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.8687 - accuracy: 0.7198\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.7359 - accuracy: 0.7643\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.6627 - accuracy: 0.7891\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.6199 - accuracy: 0.8032\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5861 - accuracy: 0.8156\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5605 - accuracy: 0.8226\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 0.5392 - accuracy: 0.8293\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5250 - accuracy: 0.8351\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5144 - accuracy: 0.8393\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5057 - accuracy: 0.8415\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4890 - accuracy: 0.8490\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4863 - accuracy: 0.8492\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4767 - accuracy: 0.8504\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4688 - accuracy: 0.8544\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4627 - accuracy: 0.8554\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4557 - accuracy: 0.8582\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4575 - accuracy: 0.8590\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4471 - accuracy: 0.8610\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4434 - accuracy: 0.8630\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4416 - accuracy: 0.8631\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4393 - accuracy: 0.8642\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4350 - accuracy: 0.8663\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4256 - accuracy: 0.8697\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4263 - accuracy: 0.8683\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4227 - accuracy: 0.8694\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4216 - accuracy: 0.8711\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 0.4195 - accuracy: 0.8711\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4168 - accuracy: 0.8714\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.3167 - accuracy: 0.9070\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 2.2281 - accuracy: 0.1934\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.3684 - accuracy: 0.5358\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.8229 - accuracy: 0.7351\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.7097 - accuracy: 0.7746\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6479 - accuracy: 0.7958\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6122 - accuracy: 0.8075\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5809 - accuracy: 0.8175\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5613 - accuracy: 0.8238\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.5413 - accuracy: 0.8294\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5310 - accuracy: 0.8349\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5123 - accuracy: 0.8408\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5051 - accuracy: 0.8408\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4903 - accuracy: 0.8478\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4817 - accuracy: 0.8507\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4758 - accuracy: 0.8512\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4745 - accuracy: 0.8523\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4658 - accuracy: 0.8555\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 0.4603 - accuracy: 0.8579\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4572 - accuracy: 0.8613\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4502 - accuracy: 0.8608\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4472 - accuracy: 0.8603\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4431 - accuracy: 0.8631\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4401 - accuracy: 0.8633\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4395 - accuracy: 0.8636\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4315 - accuracy: 0.8662\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4277 - accuracy: 0.8667\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4274 - accuracy: 0.8680\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4221 - accuracy: 0.8692\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4195 - accuracy: 0.8709\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4145 - accuracy: 0.8711\n",
            "458/458 [==============================] - 2s 3ms/step - loss: 0.2951 - accuracy: 0.9139\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 2.1812 - accuracy: 0.2179\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 1.1405 - accuracy: 0.6208\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.7989 - accuracy: 0.7441\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6956 - accuracy: 0.7796\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6392 - accuracy: 0.7969\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.6105 - accuracy: 0.8075\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 0.5802 - accuracy: 0.8164\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.5638 - accuracy: 0.8226\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5490 - accuracy: 0.8282\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5319 - accuracy: 0.8343\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5193 - accuracy: 0.8374\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5104 - accuracy: 0.8402\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.5018 - accuracy: 0.8432\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4989 - accuracy: 0.8438\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4863 - accuracy: 0.8483\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4820 - accuracy: 0.8513\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4750 - accuracy: 0.8529\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4711 - accuracy: 0.8531\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4700 - accuracy: 0.8537\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4606 - accuracy: 0.8547\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 14s 7ms/step - loss: 0.4551 - accuracy: 0.8592\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4558 - accuracy: 0.8588\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4519 - accuracy: 0.8599\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4453 - accuracy: 0.8618\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4417 - accuracy: 0.8636\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 15s 8ms/step - loss: 0.4428 - accuracy: 0.8627\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4377 - accuracy: 0.8666\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4330 - accuracy: 0.8662\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 12s 7ms/step - loss: 0.4317 - accuracy: 0.8671\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 13s 7ms/step - loss: 0.4263 - accuracy: 0.8682\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2993 - accuracy: 0.9128\n",
            "Model evaluation  [0.2992788553237915, 0.9127704501152039]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un accuracy de 90 puede ser considerado como plausible dependiendo de la tarea que se le asigne. De igual manera, la raz√≥n entre la desviaci√≥n est√°ndar de la media apuntan a que dicho accuracy posee una estabilidad sustancial (<1%)."
      ],
      "metadata": {
        "id": "UqLrzQGjGEhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(k_eval)\n",
        "print(\"Mean accuracy: \", result.mean())\n",
        "print(\"Standard deviation: \", result.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUUEIboYKyDo",
        "outputId": "5771bfb4-e7e5-42b0-db77-4b1c8679c19a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy:  0.909251081943512\n",
            "Standard deviation:  0.004986134754204118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se muestan los resultados sobre el set de prueba provisto por el dataset. Es notable que tuvo un accuracy sustancialmente m√°s alto que el promedio del KFold. Esto puede deberse a la capa de data augmentation que altera las im√°genes para prevenir overfitting sobre el set de entrenamiento, pero que resulta ben√©fico para su desempe√±o en datos no vistos previamente."
      ],
      "metadata": {
        "id": "UkIBwHgNHJH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = m1.evaluate(x=test_images, y=test_labels, verbose=0)\n",
        "\n",
        "print('Test accuracy is: {:0.4f} \\nTest loss is: {:0.4f}'.\n",
        "      format(test_acc, test_loss))"
      ],
      "metadata": {
        "id": "_8yGk8oT08qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a392201-d079-493d-fa09-fbe622b945c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is: 0.9303 \n",
            "Test loss is: 0.2499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segundo modelo (posibles mejoras)\n",
        "\n",
        "### Hacer la red m√°s profunda\n",
        "\n",
        "El primer modelo consta de 6 capas de convolusi√≥n, 3 con un tama√±o de output de 32 y 3 de tama√±o de 64. Entonces, una primera propuesta es hacer la red m√°s profunda agregando otras tres capas de convolusi√≥n con tama√±o de output mayor (128), para que se mantenga la complejidad de las capas intermedias. (densidad de output intermedio). Esto implica tener m√°s par√°metros para interpretar diferencias m√°s sutiles.\n",
        "\n",
        "### Agregar skip connections\n",
        "\n",
        "Al hacer la red m√°s profunda nos podemos encontrar con problemas de variabilidad no deseada en el gradiente de la funci√≥n de costo (shattered gradient), por lo que conexiones residuales pueden ayudar a aminorar este fen√≥meno.\n",
        "\n",
        "### Agregar una capa densa al final\n",
        "\n",
        "Aunque es posible que una red densa provoque overfitting al aprender las caracter√≠sticas proporcionadas por las CNN, podr√≠a ser √∫til para mejorar el accuracy un poco m√°s en caso de que la CNN por s√≠ sola no alcance resultados deseados.\n",
        "\n",
        "### Alinear Max-Pooling con la red que incrementa el n√∫mero de kernels\n",
        "\n",
        "Aunque el beneficio no sea asegurado, se puede interpretar como la multiplicaci√≥n del n√∫mero de celdas que un kernel \"ve\" en cada uno de los inputs y el n√∫mero de kernel per se. Si se mantiene el n√∫mero de kernels despu√©s de un Max Pooling, dichos kernels ver√°n una simplificaci√≥n de los inputs anteriores y probablemente carezcan de informaci√≥n valiosa, y esto se propagar√° a las capas siguientes. Esto asume que la informaci√≥n perdida por el Max Pooling en efecto es significativa, pero se sigue tomando las ventajas del pooling aplic√°ndolo en un momento m√°s oportuno.\n"
      ],
      "metadata": {
        "id": "HkKTPxfqIAiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bC3kSRUTmKo7"
      },
      "outputs": [],
      "source": [
        "def M2():    \n",
        "    input = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "    data_augmentation = keras.Sequential(\n",
        "        [\n",
        "            layers.RandomRotation(0.2),\n",
        "            layers.RandomZoom(0.2),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    x = data_augmentation(input)\n",
        "\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "    for size in [32, 64, 128]:\n",
        "        residual = x\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "        x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "        \n",
        "\n",
        "        residual = layers.Conv2D(\n",
        "            size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "\n",
        "        x = layers.add([x, residual])\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "    model2 = keras.Model(inputs=input, outputs=outputs)\n",
        "    return model2\n",
        "\n",
        "model2 = M2()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al tratarse de una red algo m√°s profunda, se reducir√° un poco el learning rate respecto al anterior para aminorar un posible fen√≥mento de exploding gradient."
      ],
      "metadata": {
        "id": "IFUqj81YYkDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vUPHuUW8muCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790a4691-eb73-4f34-d216-d3f673d9b5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
        "optimizer = keras.optimizers.Adam(lr=.0008, amsgrad=True)\n",
        "model2.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H_wVQEWm2Vi",
        "outputId": "d4bb2eee-e04e-4f5b-967e-feeb859d6f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "487/487 [==============================] - 13s 26ms/step - loss: 2.1549 - accuracy: 0.2266 - val_loss: 1.3844 - val_accuracy: 0.5507\n",
            "Epoch 2/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 1.0326 - accuracy: 0.6600 - val_loss: 0.5862 - val_accuracy: 0.8145\n",
            "Epoch 3/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.6635 - accuracy: 0.7868 - val_loss: 0.4313 - val_accuracy: 0.8692\n",
            "Epoch 4/40\n",
            "487/487 [==============================] - 15s 30ms/step - loss: 0.5475 - accuracy: 0.8281 - val_loss: 0.4215 - val_accuracy: 0.8702\n",
            "Epoch 5/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.4951 - accuracy: 0.8437 - val_loss: 0.3382 - val_accuracy: 0.8990\n",
            "Epoch 6/40\n",
            "487/487 [==============================] - 13s 26ms/step - loss: 0.4597 - accuracy: 0.8559 - val_loss: 0.3207 - val_accuracy: 0.9051\n",
            "Epoch 7/40\n",
            "487/487 [==============================] - 14s 28ms/step - loss: 0.4270 - accuracy: 0.8668 - val_loss: 0.3136 - val_accuracy: 0.9063\n",
            "Epoch 8/40\n",
            "487/487 [==============================] - 14s 28ms/step - loss: 0.4092 - accuracy: 0.8727 - val_loss: 0.3341 - val_accuracy: 0.8993\n",
            "Epoch 9/40\n",
            "487/487 [==============================] - 14s 28ms/step - loss: 0.3916 - accuracy: 0.8794 - val_loss: 0.2962 - val_accuracy: 0.9114\n",
            "Epoch 10/40\n",
            "487/487 [==============================] - 13s 26ms/step - loss: 0.3785 - accuracy: 0.8833 - val_loss: 0.2869 - val_accuracy: 0.9168\n",
            "Epoch 11/40\n",
            "487/487 [==============================] - 14s 28ms/step - loss: 0.3626 - accuracy: 0.8886 - val_loss: 0.2751 - val_accuracy: 0.9196\n",
            "Epoch 12/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3535 - accuracy: 0.8921 - val_loss: 0.2704 - val_accuracy: 0.9232\n",
            "Epoch 13/40\n",
            "487/487 [==============================] - 13s 26ms/step - loss: 0.3499 - accuracy: 0.8939 - val_loss: 0.2636 - val_accuracy: 0.9229\n",
            "Epoch 14/40\n",
            "487/487 [==============================] - 14s 28ms/step - loss: 0.3334 - accuracy: 0.8985 - val_loss: 0.2535 - val_accuracy: 0.9275\n",
            "Epoch 15/40\n",
            "487/487 [==============================] - 14s 29ms/step - loss: 0.3316 - accuracy: 0.8993 - val_loss: 0.2558 - val_accuracy: 0.9260\n",
            "Epoch 16/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3235 - accuracy: 0.9024 - val_loss: 0.2587 - val_accuracy: 0.9262\n",
            "Epoch 17/40\n",
            "487/487 [==============================] - 13s 27ms/step - loss: 0.3183 - accuracy: 0.9032 - val_loss: 0.2458 - val_accuracy: 0.9285\n",
            "Epoch 18/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3117 - accuracy: 0.9058 - val_loss: 0.2383 - val_accuracy: 0.9307\n",
            "Epoch 19/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3103 - accuracy: 0.9051 - val_loss: 0.2431 - val_accuracy: 0.9321\n",
            "Epoch 20/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.3035 - accuracy: 0.9077 - val_loss: 0.2532 - val_accuracy: 0.9274\n",
            "Epoch 21/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2963 - accuracy: 0.9097 - val_loss: 0.2421 - val_accuracy: 0.9297\n",
            "Epoch 22/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2982 - accuracy: 0.9097 - val_loss: 0.2397 - val_accuracy: 0.9342\n",
            "Epoch 23/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2884 - accuracy: 0.9117 - val_loss: 0.2274 - val_accuracy: 0.9348\n",
            "Epoch 24/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2845 - accuracy: 0.9136 - val_loss: 0.2305 - val_accuracy: 0.9350\n",
            "Epoch 25/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2842 - accuracy: 0.9152 - val_loss: 0.2293 - val_accuracy: 0.9340\n",
            "Epoch 26/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2823 - accuracy: 0.9142 - val_loss: 0.2281 - val_accuracy: 0.9339\n",
            "Epoch 27/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2733 - accuracy: 0.9169 - val_loss: 0.2227 - val_accuracy: 0.9362\n",
            "Epoch 28/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2712 - accuracy: 0.9178 - val_loss: 0.2433 - val_accuracy: 0.9322\n",
            "Epoch 29/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2725 - accuracy: 0.9184 - val_loss: 0.2262 - val_accuracy: 0.9370\n",
            "Epoch 30/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2690 - accuracy: 0.9195 - val_loss: 0.2282 - val_accuracy: 0.9358\n",
            "Epoch 31/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2683 - accuracy: 0.9200 - val_loss: 0.2282 - val_accuracy: 0.9353\n",
            "Epoch 32/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2627 - accuracy: 0.9207 - val_loss: 0.2221 - val_accuracy: 0.9363\n",
            "Epoch 33/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2623 - accuracy: 0.9211 - val_loss: 0.2205 - val_accuracy: 0.9378\n",
            "Epoch 34/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2606 - accuracy: 0.9210 - val_loss: 0.2193 - val_accuracy: 0.9386\n",
            "Epoch 35/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2572 - accuracy: 0.9218 - val_loss: 0.2156 - val_accuracy: 0.9402\n",
            "Epoch 36/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2499 - accuracy: 0.9242 - val_loss: 0.2139 - val_accuracy: 0.9373\n",
            "Epoch 37/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2491 - accuracy: 0.9256 - val_loss: 0.2131 - val_accuracy: 0.9401\n",
            "Epoch 38/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2518 - accuracy: 0.9238 - val_loss: 0.2138 - val_accuracy: 0.9408\n",
            "Epoch 39/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2468 - accuracy: 0.9263 - val_loss: 0.2215 - val_accuracy: 0.9398\n",
            "Epoch 40/40\n",
            "487/487 [==============================] - 12s 25ms/step - loss: 0.2461 - accuracy: 0.9256 - val_loss: 0.2110 - val_accuracy: 0.9418\n"
          ]
        }
      ],
      "source": [
        "history2 = model2.fit(X_train, y_train, batch_size=128, \n",
        "                      epochs=40, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No se observa underfitting u overfitting al igual que en el primer modelo (no se separan las l√≠neas). No obstante, los valores de accuracy tanto de entrenamiento como validaci√≥n son superiores. Incluso la separaci√≥n entre √©stas es menor. Esto indica un \"fit\" superior. Adem√°s, el accuracy de validaci√≥n se estabiliza m√°s r√°pido que en la primera arquitectura."
      ],
      "metadata": {
        "id": "KDMoLWiGcpBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = history2.history['accuracy']\n",
        "val_acc = history2.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Epochs vs. Training and Validation Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "idF_8vR-ciuT",
        "outputId": "5a913aac-471b-4a83-a2fc-2d699cad6dc8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Epochs vs. Training and Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n\n",
        "\n",
        "Se proceder√° a realizar la mismo procedimiento de KFold cross-validation que el modelo anterior. (k=5)"
      ],
      "metadata": {
        "id": "mryosiRXY5Dq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1De5B4mCGY6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82d58d4-328b-4de4-ab1b-c6e2c4e8b800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 20s 10ms/step - loss: 2.0819 - accuracy: 0.3306\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 1.0439 - accuracy: 0.6600\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.7649 - accuracy: 0.7538\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.6432 - accuracy: 0.7933\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5639 - accuracy: 0.8217\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5108 - accuracy: 0.8393\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4769 - accuracy: 0.8500\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4507 - accuracy: 0.8590\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4193 - accuracy: 0.8687\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4063 - accuracy: 0.8737\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3894 - accuracy: 0.8802\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3783 - accuracy: 0.8828\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3695 - accuracy: 0.8863\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3622 - accuracy: 0.8874\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3486 - accuracy: 0.8924\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3434 - accuracy: 0.8946\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.3365 - accuracy: 0.8976\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3330 - accuracy: 0.8981\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3260 - accuracy: 0.9007\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3186 - accuracy: 0.9016\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3147 - accuracy: 0.9032\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3085 - accuracy: 0.9058\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3078 - accuracy: 0.9059\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3044 - accuracy: 0.9057\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2997 - accuracy: 0.9082\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2931 - accuracy: 0.9103\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2903 - accuracy: 0.9114\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2873 - accuracy: 0.9124\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2847 - accuracy: 0.9132\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.2808 - accuracy: 0.9139\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.2679 - accuracy: 0.9241\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 1.8269 - accuracy: 0.4112\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.8382 - accuracy: 0.7277\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.6348 - accuracy: 0.7971\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5460 - accuracy: 0.8263\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4910 - accuracy: 0.8473\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4560 - accuracy: 0.8575\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4323 - accuracy: 0.8661\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4136 - accuracy: 0.8720\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3944 - accuracy: 0.8784\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3832 - accuracy: 0.8816\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.3689 - accuracy: 0.8866\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3590 - accuracy: 0.8893\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3518 - accuracy: 0.8926\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3410 - accuracy: 0.8963\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3353 - accuracy: 0.8982\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3267 - accuracy: 0.9010\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3218 - accuracy: 0.9026\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3190 - accuracy: 0.9020\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3145 - accuracy: 0.9041\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3077 - accuracy: 0.9056\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3082 - accuracy: 0.9068\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2988 - accuracy: 0.9082\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2939 - accuracy: 0.9108\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.2909 - accuracy: 0.9115\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2890 - accuracy: 0.9128\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2818 - accuracy: 0.9149\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2828 - accuracy: 0.9146\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2803 - accuracy: 0.9149\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2747 - accuracy: 0.9165\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2755 - accuracy: 0.9170\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.2357 - accuracy: 0.9333\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 20s 10ms/step - loss: 2.1372 - accuracy: 0.2935\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 1.0593 - accuracy: 0.6512\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.7476 - accuracy: 0.7615\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.6169 - accuracy: 0.8026\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.5420 - accuracy: 0.8281\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4979 - accuracy: 0.8425\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4599 - accuracy: 0.8553\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4372 - accuracy: 0.8636\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4136 - accuracy: 0.8705\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4018 - accuracy: 0.8744\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3891 - accuracy: 0.8788\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3799 - accuracy: 0.8825\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3664 - accuracy: 0.8885\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3564 - accuracy: 0.8899\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3465 - accuracy: 0.8932\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3465 - accuracy: 0.8943\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3376 - accuracy: 0.8964\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.3286 - accuracy: 0.8996\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3223 - accuracy: 0.9013\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3212 - accuracy: 0.9019\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3111 - accuracy: 0.9048\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3072 - accuracy: 0.9056\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3039 - accuracy: 0.9067\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3022 - accuracy: 0.9083\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2986 - accuracy: 0.9102\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2910 - accuracy: 0.9119\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2894 - accuracy: 0.9111\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2865 - accuracy: 0.9145\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2858 - accuracy: 0.9138\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.2781 - accuracy: 0.9162\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2461 - accuracy: 0.9331\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 20s 10ms/step - loss: 1.9152 - accuracy: 0.3793\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.9118 - accuracy: 0.7025\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.6961 - accuracy: 0.7768\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5916 - accuracy: 0.8112\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5212 - accuracy: 0.8367\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4840 - accuracy: 0.8488\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4515 - accuracy: 0.8592\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4270 - accuracy: 0.8663\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4026 - accuracy: 0.8747\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3935 - accuracy: 0.8777\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3802 - accuracy: 0.8833\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3652 - accuracy: 0.8871\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 21s 11ms/step - loss: 0.3618 - accuracy: 0.8879\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3473 - accuracy: 0.8937\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3433 - accuracy: 0.8955\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3341 - accuracy: 0.8979\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3258 - accuracy: 0.9000\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3210 - accuracy: 0.9010\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3177 - accuracy: 0.9030\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3109 - accuracy: 0.9047\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3056 - accuracy: 0.9068\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3018 - accuracy: 0.9074\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2999 - accuracy: 0.9087\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2929 - accuracy: 0.9107\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 19s 11ms/step - loss: 0.2921 - accuracy: 0.9104\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 19s 10ms/step - loss: 0.2857 - accuracy: 0.9134\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2830 - accuracy: 0.9135\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2815 - accuracy: 0.9149\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2776 - accuracy: 0.9157\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2738 - accuracy: 0.9156\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2381 - accuracy: 0.9343\n",
            "Epoch 1/30\n",
            "1832/1832 [==============================] - 20s 10ms/step - loss: 2.0154 - accuracy: 0.3469\n",
            "Epoch 2/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 1.0327 - accuracy: 0.6585\n",
            "Epoch 3/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.7379 - accuracy: 0.7633\n",
            "Epoch 4/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.6106 - accuracy: 0.8055\n",
            "Epoch 5/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.5453 - accuracy: 0.8277\n",
            "Epoch 6/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4926 - accuracy: 0.8442\n",
            "Epoch 7/30\n",
            "1832/1832 [==============================] - 21s 11ms/step - loss: 0.4592 - accuracy: 0.8562\n",
            "Epoch 8/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4333 - accuracy: 0.8665\n",
            "Epoch 9/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.4156 - accuracy: 0.8714\n",
            "Epoch 10/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3981 - accuracy: 0.8771\n",
            "Epoch 11/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3805 - accuracy: 0.8828\n",
            "Epoch 12/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3719 - accuracy: 0.8847\n",
            "Epoch 13/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3605 - accuracy: 0.8884\n",
            "Epoch 14/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3503 - accuracy: 0.8941\n",
            "Epoch 15/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3465 - accuracy: 0.8943\n",
            "Epoch 16/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3399 - accuracy: 0.8953\n",
            "Epoch 17/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3322 - accuracy: 0.8975\n",
            "Epoch 18/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3220 - accuracy: 0.9014\n",
            "Epoch 19/30\n",
            "1832/1832 [==============================] - 20s 11ms/step - loss: 0.3196 - accuracy: 0.9033\n",
            "Epoch 20/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3145 - accuracy: 0.9050\n",
            "Epoch 21/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3118 - accuracy: 0.9045\n",
            "Epoch 22/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3091 - accuracy: 0.9070\n",
            "Epoch 23/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.3005 - accuracy: 0.9077\n",
            "Epoch 24/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2989 - accuracy: 0.9097\n",
            "Epoch 25/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2928 - accuracy: 0.9106\n",
            "Epoch 26/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2897 - accuracy: 0.9112\n",
            "Epoch 27/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2850 - accuracy: 0.9135\n",
            "Epoch 28/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2832 - accuracy: 0.9141\n",
            "Epoch 29/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2801 - accuracy: 0.9138\n",
            "Epoch 30/30\n",
            "1832/1832 [==============================] - 18s 10ms/step - loss: 0.2762 - accuracy: 0.9169\n",
            "458/458 [==============================] - 2s 4ms/step - loss: 0.2368 - accuracy: 0.9328\n",
            "Model evaluation  [0.23676173388957977, 0.9327691197395325]\n"
          ]
        }
      ],
      "source": [
        "n_split = 5\n",
        "k_eval = []\n",
        "\n",
        "for train_i ,val_i in KFold(n_split).split(train_images):\n",
        "  x_train,x_val= train_images[train_i], train_images[val_i]\n",
        "  y_t,y_v= train_labels[train_i], train_labels[val_i]\n",
        "\n",
        "  aux = M2()\n",
        "\n",
        "  aux.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  aux.fit(x_train, y_t,epochs=30)\n",
        "\n",
        "  eval = aux.evaluate(x_val,y_v)\n",
        "  k_eval.append(eval[1])\n",
        "\n",
        "print('Model evaluation ', eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo que implementa las sugerencias present√≥ un incremento de .03 apr√≥ximadamente y mantuvo una relaci√≥n con la desviaci√≥n est√°ndar similar al primer modelo (<1%). Esto es una mejora significativa."
      ],
      "metadata": {
        "id": "yZPhrhfnZa1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(k_eval)\n",
        "print(\"Mean accuracy: \", result.mean())\n",
        "print(\"Standard deviation: \", result.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqK6zGZxf2l_",
        "outputId": "b9eadda6-9b71-40ac-a5d3-17d5c792ebe5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy:  0.9315151572227478\n",
            "Standard deviation:  0.00373798836209485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente se muestra el desempe√±o de la versi√≥n entrenada por 40 √©pocas sobre el set de prueba. El accuracy increment√≥ .015 aproximadamente , aunque no fue la misma magnitud incremental que en los set de validaci√≥n, a√∫n fue una mejora significativa. Se tendr√≠a tambi√©n que evaluar ambos modelos al entrenarse en todav√≠a m√°s √©pocas para conocer su convergencia."
      ],
      "metadata": {
        "id": "t0nSxNM6agEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model2.evaluate(x=test_images, y=test_labels, verbose=0)\n",
        "\n",
        "print('Test accuracy is: {:0.4f} \\nTest loss is: {:0.4f}'.\n",
        "      format(test_acc, test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjuz9c2kuOQY",
        "outputId": "153c9362-dc33-404e-945b-2bf9dc42e6a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is: 0.9446 \n",
            "Test loss is: 0.1997\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}